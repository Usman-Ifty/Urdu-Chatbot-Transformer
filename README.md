ğŸ—£ï¸ Urdu Chatbot â€” Transformer with Multi-Head Attention

A Transformer-based Urdu Conversational Chatbot built completely from scratch using PyTorch, trained on an Urdu dialogue dataset and deployed with a Streamlit web interface for real-time interaction.

This project demonstrates an end-to-end Natural Language Processing (NLP) pipeline â€” from text normalization and tokenization, to training, evaluation, and web deployment â€” optimized for Urdu text generation.

ğŸ§  Project Overview

The goal of this project is to design and implement a sequence-to-sequence Transformer capable of understanding and generating coherent Urdu sentences without relying on pre-trained language models.

It uses:

Encoder-Decoder Transformer architecture

Multi-Head Attention for contextual representation

SentencePiece Tokenization for subword-level Urdu handling

Beam Search & Greedy decoding

Streamlit Interface for live Urdu conversation

ğŸš€ Key Features

âœ… Built from scratch using PyTorch
âœ… Handles Urdu text (right-to-left) using Unicode
âœ… Custom SentencePiece tokenizer (urdu_tokenizer.model)
âœ… Real-time chat via Streamlit Web App
âœ… Multiple decoding options (Beam Search / Greedy)
âœ… Automatic masking & positional encoding
âœ… Modular Transformer implementation (Encoder + Decoder)
âœ… Supports state_dict checkpoint loading (urdu_chatbot.pt)

ğŸ—ï¸ Architecture Summary
Component	Description
Embedding Dim	128
Encoder Layers	2
Decoder Layers	2
Attention Heads	4
Feed-Forward Dim	512
Dropout	0.2
BOS / EOS IDs	2 / 3
Optimizer	Adam (lr = 1e-4)
Loss Function	Cross Entropy
ğŸ“‚ Repository Structure
Urdu-Chatbot-Transformer/
â”‚
â”œâ”€â”€ app.py                   # Streamlit chatbot app (inference)
â”œâ”€â”€ urdu_chatbot.pt          # Trained model checkpoint (state_dict)
â”œâ”€â”€ urdu_tokenizer.model     # SentencePiece tokenizer
â”œâ”€â”€ normalized_sentences.csv # Urdu conversational dataset
â”œâ”€â”€ nlpass2.ipynb            # Model training notebook
â””â”€â”€ README.md                # Project documentation

ğŸ§° Requirements

Install required packages before running:

pip install torch streamlit sentencepiece sacrebleu rouge-score


(Optionally, you can create a requirements.txt with the same list.)

â–¶ï¸ Running the Chatbot Locally

Activate your virtual environment

.venv\Scripts\activate       # Windows
# or
source .venv/bin/activate    # macOS/Linux


Run the app

streamlit run app.py


Open the local URL shown in the terminal:
ğŸ‘‰ http://localhost:8501

Enter Urdu text such as:

Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…! Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’ØŸ
Ø¢Ø¬ Ù…ÙˆØ³Ù… Ú©ÛŒØ³Ø§ ÛÛ’ØŸ
ØªÙ…ÛÛŒÚº Ú©Ø³ Ù†Û’ Ø¨Ù†Ø§ÛŒØ§ØŸ

ğŸ’¬ Sample Interaction

User:

Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÛŒÚ©Ù…! Ú©ÛŒØ§ Ø­Ø§Ù„ ÛÛ’ØŸ


Chatbot:

ÙˆØ¹Ù„ÛŒÚ©Ù… Ø§Ù„Ø³Ù„Ø§Ù…! Ù…ÛŒÚº Ù¹Ú¾ÛŒÚ© ÛÙˆÚºØŒ Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ


(Responses may vary depending on model training.)

ğŸ§ª Training Details (from nlpass2.ipynb)

Dataset: 20,000 Urdu sentence pairs (normalized + cleaned)

Tokenizer: SentencePiece (vocab_size=16000)

Split: Train 80%, Val 10%, Test 10%

Epochs: 10 (extendable to 25+)

Batch Size: 32

Learning Rate: 1e-4

Loss: Cross Entropy

Metrics: BLEU, ROUGE-L, chrF, Perplexity

The model captures Urdu linguistic structure successfully but requires longer training for fluent and contextually accurate replies.

ğŸŒ Streamlit UI Features

Right-to-Left Urdu input box

Display of conversation history

Sidebar configuration:

Checkpoint path (urdu_chatbot.pt)

Tokenizer path (urdu_tokenizer.model)

Decoding mode (Greedy / Beam Search)

Adjustable beam size & max token length

Real-time generation feedback with spinners

Clean conversational layout

ğŸ§­ How to Deploy on Streamlit Cloud

Push all project files to GitHub
ğŸ‘‰ https://github.com/Usman-Ifty/Urdu-Chatbot-Transformer

Go to https://share.streamlit.io

Connect your GitHub account

Select repository: Usman-Ifty/Urdu-Chatbot-Transformer

Entry file: app.py

Click Deploy

Youâ€™ll receive a live link such as:
https://usman-ifty-urdu-chatbot-transformer.streamlit.app

âš™ï¸ Troubleshooting
Issue	Cause	Fix
Random Urdu words	Undertrained model (10 epochs)	Retrain for â‰¥ 25 epochs
Streamlit shows â€œstate_dict mismatchâ€	FeedForward layer renamed	Use w1/w2 instead of linear1/linear2
Tokenizer loads but output gibberish	Wrong .model file	Use the exact same tokenizer from training
Long unreadable output	Missing EOS ID	Ensure BOS=2, EOS=3
ğŸ“ˆ Future Work

Fine-tune model for 25+ epochs

Add more Urdu conversational data

Visualize attention heatmaps

Implement top-k / nucleus sampling decoding

Improve contextual memory across turns

Deploy fully on Streamlit Cloud with persistent chat history

ğŸ§‘â€ğŸ’» Author

Muhammad Usman Awan
FAST-NUCES, Chiniot-Faisalabad Campus
BSCS â€“ Semester 7
GitHub: Usman-Ifty

ğŸ“œ License

MIT License Â© 2025 Muhammad Usman Awan

â­ GitHub Repository

ğŸ”— https://github.com/Usman-Ifty/Urdu-Chatbot-Transformer